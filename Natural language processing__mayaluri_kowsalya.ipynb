{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXRcePjUGlM7",
    "outputId": "c083f3b3-dff9-4027-cb0d-0edeac984bf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kq7vbtAsIP3f",
    "outputId": "85751432-a313-4483-eb1e-e365bc8af097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep-translator\n",
      "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.8.30)\n",
      "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m615.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: deep-translator\n",
      "Successfully installed deep-translator-1.11.4\n"
     ]
    }
   ],
   "source": [
    "pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MfG_opRHIZ89",
    "outputId": "ff4f6842-90ff-41fe-ce51-9bd63dd717e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.8.1\n"
     ]
    }
   ],
   "source": [
    "pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLyOpCIwIgQ0",
    "outputId": "dcc0f558-04c5-47ce-a324-fca02a454f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0-rc1\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.8.30)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hstspreload-2024.9.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2024.9.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=171aee9ab03d54f93fcf39671fb6367b3640c4280b626611372ef7e27a5e7df8\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 5.2.0\n",
      "    Uninstalling chardet-5.2.0:\n",
      "      Successfully uninstalled chardet-5.2.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.8\n",
      "    Uninstalling idna-3.8:\n",
      "      Successfully uninstalled idna-3.8\n",
      "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.9.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFJ5z3IvIqRE",
    "outputId": "52f2bf11-da39-46dd-c37c-cd3a69ea44d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Sample Document</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>Welcome to Text Preprocessing!</h1>\n",
      "    <p>Text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization.</p>\n",
      "    <p>Data from different sources might include HTML tags, special characters like @, #, &, and emojis üòä.</p>\n",
      "    <p>Consider this sample sentence: \"I can't believe it's already 2023! Text processing is awesome, isn't it?\"</p>\n",
      "    <p>Also, names like maya, New Haven, and companies such as apple are common entities in texts.</p>\n",
      "    <p>typos like this sentence need correction, and so does spelling.</p>\n",
      "  </body>\n",
      "</html>\n",
      "A computer is one of the best man-made creations that has been developed to help people in various sectors. It has become such an important part of our lives that we find computers everywhere we go. Starting from our school life till our old age, we have many uses for computers. We have become so much dependent on computers that we are using computers for almost everything we do. It is a device that can store an enormous amount of data in it. We are so much dependent on computers that we do not want to put any pressure on ourselves. We blindly store all our data in a computer with a safety passcode. A computer takes up the responsibility and processes the output in no time, hence making our life easier. It collects the data, processes it and then provides the final result to us within a very short time. People in this day and age have become so reliant on computers that they cannot imagine life without them. Computers are significant because of their widespread use, productivity, and openness. Computers are the most needed innovation due to their incredible benefits. Computers are used in every field, like the education sector, hospitals, hotels, etc. If you go for a CT Scan, X-ray, or ECG, you will need a computer to check your body. In case you want to submit a project, you will need a computer. It has become a part of our lifestyle.\n",
      "\n",
      "The computer is a remarkable piece of science that man has created to help humanity. Computers are in charge of today‚Äôs reality, and they have unquestionably altered people‚Äôs lifestyles and the condition of developing countries.\n",
      "\n",
      "In the 21st century, it is impossible to imagine a life without a computer and internet connection. The invention of computers has brought a lot of changes in people‚Äôs lives and has helped in fulfilling people‚Äôs dreams. A computer is used in various organisations, schools, institutions, offices, etc. It can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive emails, etc. The major parts of a computer are the mouse, keyboard, monitor, and CPU, but these gadgets have been improvised with a lot of modifications.\n",
      "\n",
      "Nowadays, we have become very dependent on technology; therefore, it is difficult to imagine our lives without a computer. To learn any professional course, you must be well-versed in computer usage. Whether a school student or an employee, you must at least know the basics of computers. Along with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc. With the increasing usage and demands of people, computers have been developed and have made life easier. Starting from simple calculations to weather forecasting, computers have become a part of our lives.\n"
     ]
    }
   ],
   "source": [
    "with open('sample.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "akHYbn7qI4EK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sample.txt', sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGoDA6usJyrt",
    "outputId": "4378a7b6-b7c2-4d9f-9e37-dc228b41ab2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "\n",
      "<html>\n",
      "\n",
      "  <head>\n",
      "\n",
      "    <title>Sample Document</title>\n",
      "\n",
      "  </head>\n",
      "\n",
      "  <body>\n",
      "\n",
      "    <h1>Welcome to Text Preprocessing!</h1>\n",
      "\n",
      "    <p>Text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization.</p>\n",
      "\n",
      "    <p>Data from different sources might include HTML tags, special characters like @, #, &, and emojis üòä.</p>\n",
      "\n",
      "    <p>Consider this sample sentence: \"I can't believe it's already 2023! Text processing is awesome, isn't it?\"</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('sample.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Print the first few lines to inspect\n",
    "for line in lines[:10]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-eYF9PFI_zR",
    "outputId": "ac9a9480-6950-4c8b-b4cc-66f0a9341463"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     <!DOCTYPE html>\n",
      "0                                             <html>\n",
      "1                                             <head>\n",
      "2                     <title>Sample Document</title>\n",
      "3                                            </head>\n",
      "4                                             <body>\n",
      "5            <h1>Welcome to Text Preprocessing!</h1>\n",
      "6      <p>Text preprocessing involves various ste...\n",
      "7      <p>Data from different sources might inclu...\n",
      "8      <p>Consider this sample sentence: \"I can't...\n",
      "9      <p>Also, names like maya, New Haven, and c...\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <!DOCTYPE html>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <html>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <head>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <title>Sample Document</title>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </head>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <body>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <h1>Welcome to Text Preprocessing!</h1>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   <p>Text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <p>Data from different sources might include HTML tags, special characters like @, #, &, and emojis üòä.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  <p>Consider this sample sentence: \"I can't believe it's already 2023! Text processing is awesome, isn't it?\"</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <p>Also, names like maya, New Haven, and companies such as apple are common entities in texts.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       <p>typos like this sentence need correction, and so does spelling.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </body>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </html>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "| A computer is one of the best man-made creations that has been developed to help people in various sectors. It has become such an important part of our lives that we find computers everywhere we go. Starting from our school life till our old age, we have many uses for computers. We have become so much dependent on computers that we are using computers for almost everything we do. It is a device that can store an enormous amount of data in it. We are so much dependent on computers that we do not want to put any pressure on ourselves. We blindly store all our data in a computer with a safety passcode. A computer takes up the responsibility and processes the output in no time, hence making our life easier. It collects the data, processes it and then provides the final result to us within a very short time. People in this day and age have become so reliant on computers that they cannot imagine life without them. Computers are significant because of their widespread use, productivity, and openness. Computers are the most needed innovation due to their incredible benefits. Computers are used in every field, like the education sector, hospitals, hotels, etc. If you go for a CT Scan, X-ray, or ECG, you will need a computer to check your body. In case you want to submit a project, you will need a computer. It has become a part of our lifestyle. |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The computer is a remarkable piece of science that man has created to help humanity. Computers are in charge of today‚Äôs reality, and they have unquestionably altered people‚Äôs lifestyles and the condition of developing countries.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                              In the 21st century, it is impossible to imagine a life without a computer and internet connection. The invention of computers has brought a lot of changes in people‚Äôs lives and has helped in fulfilling people‚Äôs dreams. A computer is used in various organisations, schools, institutions, offices, etc. It can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive emails, etc. The major parts of a computer are the mouse, keyboard, monitor, and CPU, but these gadgets have been improvised with a lot of modifications.                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "|                                                                                                                                                                                                                                                                                                                                                                  Nowadays, we have become very dependent on technology; therefore, it is difficult to imagine our lives without a computer. To learn any professional course, you must be well-versed in computer usage. Whether a school student or an employee, you must at least know the basics of computers. Along with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc. With the increasing usage and demands of people, computers have been developed and have made life easier. Starting from simple calculations to weather forecasting, computers have become a part of our lives.                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Download NLTK data if not already present\n",
    "def download_nltk_resources():\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "# Read data from a CSV file with error handling\n",
    "def read_csv_file(file_path, delimiter='\\t'):\n",
    "    try:\n",
    "        return pd.read_csv(file_path, sep=delimiter, on_bad_lines='skip')\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing file: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of error\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "def display_head(df, rows=10):\n",
    "    print(df.head(rows))\n",
    "\n",
    "def main():\n",
    "    # Define file paths\n",
    "    input_file_path = 'sample.txt'\n",
    "    output_file_path = 'review.txt'\n",
    "\n",
    "    # Download necessary NLTK resources\n",
    "    download_nltk_resources()\n",
    "\n",
    "    # Read the CSV file with correct delimiter\n",
    "    df = read_csv_file(input_file_path)  # Use the correct delimiter '\\t'\n",
    "\n",
    "    # Display the first 10 rows of the DataFrame\n",
    "    display_head(df)\n",
    "\n",
    "    # Optionally save to a new file\n",
    "    df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "    # Print the DataFrame using PrettyTable\n",
    "    table = PrettyTable()\n",
    "    table.field_names = df.columns\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        table.add_row(row)\n",
    "\n",
    "    print(table)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Text Extraction and Cleanup\n",
    "The code reads text from a file, removes HTML tags, special characters, and extra whitespace, normalizing it for cleaner output. It uses regular expressions for these tasks and outputs both the original and cleaned text. The text_cleanup function focuses on basic text cleaning and formatting adjustments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1C2aik7KSTI",
    "outputId": "4b084956-80d4-41ed-9e55-d2fb31b58aef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Sample Document</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>Welcome to Text Preprocessing!</h1>\n",
      "    <p>Text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization.</p>\n",
      "    <p>Data from different sources might include HTML tags, special characters like @, #, &, and emojis üòä.</p>\n",
      "    <p>Consider this sample sentence: \"I can't believe it's already 2023! Text processing is awesome, isn't it?\"</p>\n",
      "    <p>Also, names like maya, New Haven, and companies such as apple are common entities in texts.</p>\n",
      "    <p>typos like this sentence need correction, and so does spelling.</p>\n",
      "  </body>\n",
      "</html>\n",
      "A computer is one of the best man-made creations that has been developed to help people in various sectors. It has become such an important part of our lives that we find computers everywhere we go. Starting from our school life till our old age, we have many uses for computers. We have become so much dependent on computers that we are using computers for almost everything we do. It is a device that can store an enormous amount of data in it. We are so much dependent on computers that we do not want to put any pressure on ourselves. We blindly store all our data in a computer with a safety passcode. A computer takes up the responsibility and processes the output in no time, hence making our life easier. It collects the data, processes it and then provides the final result to us within a very short time. People in this day and age have become so reliant on computers that they cannot imagine life without them. Computers are significant because of their widespread use, productivity, and openness. Computers are the most needed innovation due to their incredible benefits. Computers are used in every field, like the education sector, hospitals, hotels, etc. If you go for a CT Scan, X-ray, or ECG, you will need a computer to check your body. In case you want to submit a project, you will need a computer. It has become a part of our lifestyle.\n",
      "\n",
      "The computer is a remarkable piece of science that man has created to help humanity. Computers are in charge of today‚Äôs reality, and they have unquestionably altered people‚Äôs lifestyles and the condition of developing countries.\n",
      "\n",
      "In the 21st century, it is impossible to imagine a life without a computer and internet connection. The invention of computers has brought a lot of changes in people‚Äôs lives and has helped in fulfilling people‚Äôs dreams. A computer is used in various organisations, schools, institutions, offices, etc. It can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive emails, etc. The major parts of a computer are the mouse, keyboard, monitor, and CPU, but these gadgets have been improvised with a lot of modifications.\n",
      "\n",
      "Nowadays, we have become very dependent on technology; therefore, it is difficult to imagine our lives without a computer. To learn any professional course, you must be well-versed in computer usage. Whether a school student or an employee, you must at least know the basics of computers. Along with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc. With the increasing usage and demands of people, computers have been developed and have made life easier. Starting from simple calculations to weather forecasting, computers have become a part of our lives.\n",
      "\n",
      "Cleaned Text:\n",
      "Sample Document Welcome to Text Preprocessing! Text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization. Data from different sources might include HTML tags, special characters like , , , and emojis . Consider this sample sentence I can't believe it's already 2023! Text processing is awesome, isn't it? Also, names like maya, New Haven, and companies such as apple are common entities in texts. typos like this sentence need correction, and so does spelling. A computer is one of the best manmade creations that has been developed to help people in various sectors. It has become such an important part of our lives that we find computers everywhere we go. Starting from our school life till our old age, we have many uses for computers. We have become so much dependent on computers that we are using computers for almost everything we do. It is a device that can store an enormous amount of data in it. We are so much dependent on computers that we do not want to put any pressure on ourselves. We blindly store all our data in a computer with a safety passcode. A computer takes up the responsibility and processes the output in no time, hence making our life easier. It collects the data, processes it and then provides the final result to us within a very short time. People in this day and age have become so reliant on computers that they cannot imagine life without them. Computers are significant because of their widespread use, productivity, and openness. Computers are the most needed innovation due to their incredible benefits. Computers are used in every field, like the education sector, hospitals, hotels, etc. If you go for a CT Scan, Xray, or ECG, you will need a computer to check your body. In case you want to submit a project, you will need a computer. It has become a part of our lifestyle. The computer is a remarkable piece of science that man has created to help humanity. Computers are in charge of todays reality, and they have unquestionably altered peoples lifestyles and the condition of developing countries. In the 21st century, it is impossible to imagine a life without a computer and internet connection. The invention of computers has brought a lot of changes in peoples lives and has helped in fulfilling peoples dreams. A computer is used in various organisations, schools, institutions, offices, etc. It can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive emails, etc. The major parts of a computer are the mouse, keyboard, monitor, and CPU, but these gadgets have been improvised with a lot of modifications. Nowadays, we have become very dependent on technology therefore, it is difficult to imagine our lives without a computer. To learn any professional course, you must be wellversed in computer usage. Whether a school student or an employee, you must at least know the basics of computers. Along with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc. With the increasing usage and demands of people, computers have been developed and have made life easier. Starting from simple calculations to weather forecasting, computers have become a part of our lives.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def text_cleanup(text):\n",
    "    \"\"\"\n",
    "    Clean the input text by removing HTML tags, special characters, and extra whitespace.\n",
    "\n",
    "    Args:\n",
    "        text (str): The raw input text to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Remove special characters (excluding alphanumeric characters, spaces, and basic punctuation)\n",
    "    text = re.sub(r'[^A-Za-z0-9.,!?\\'\\s]', '', text)\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    #  path the sample text file\n",
    "    file_path = 'sample.txt'\n",
    "\n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "\n",
    "    # Clean the text\n",
    "    cleaned_text = text_cleanup(text)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Original Text:\")\n",
    "    print(text)\n",
    "    print(\"\\nCleaned Text:\")\n",
    "    print(cleaned_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Synonym Replacement\n",
    "The synonym replacement code uses wordnet from NLTK to find synonyms for words in a given text. It tokenizes the text, finds the first synonym for each word, and replaces the word if a valid synonym is found. The process ensures that only words are replaced, leaving non-alphabetic tokens unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kt4_EstFLdbg",
    "outputId": "8215bed7-5824-4f55-a6fb-ecf62d35d6e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Sample Document</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>Welcome to Text Preprocessing!</h1>\n",
      "    <p>Text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization.</p>\n",
      "    <p>Data from different sources might include HTML tags, special characters like @, #, &, and emojis üòä.</p>\n",
      "    <p>Consider this sample sentence: \"I can't believe it's already 2023! Text processing is awesome, isn't it?\"</p>\n",
      "    <p>Also, names like maya, New Haven, and companies such as apple are common entities in texts.</p>\n",
      "    <p>typos like this sentence need correction, and so does spelling.</p>\n",
      "  </body>\n",
      "</html>\n",
      "A computer is one of the best man-made creations that has been developed to help people in various sectors. It has become such an important part of our lives that we find computers everywhere we go. Starting from our school life till our old age, we have many uses for computers. We have become so much dependent on computers that we are using computers for almost everything we do. It is a device that can store an enormous amount of data in it. We are so much dependent on computers that we do not want to put any pressure on ourselves. We blindly store all our data in a computer with a safety passcode. A computer takes up the responsibility and processes the output in no time, hence making our life easier. It collects the data, processes it and then provides the final result to us within a very short time. People in this day and age have become so reliant on computers that they cannot imagine life without them. Computers are significant because of their widespread use, productivity, and openness. Computers are the most needed innovation due to their incredible benefits. Computers are used in every field, like the education sector, hospitals, hotels, etc. If you go for a CT Scan, X-ray, or ECG, you will need a computer to check your body. In case you want to submit a project, you will need a computer. It has become a part of our lifestyle.\n",
      "\n",
      "The computer is a remarkable piece of science that man has created to help humanity. Computers are in charge of today‚Äôs reality, and they have unquestionably altered people‚Äôs lifestyles and the condition of developing countries.\n",
      "\n",
      "In the 21st century, it is impossible to imagine a life without a computer and internet connection. The invention of computers has brought a lot of changes in people‚Äôs lives and has helped in fulfilling people‚Äôs dreams. A computer is used in various organisations, schools, institutions, offices, etc. It can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive emails, etc. The major parts of a computer are the mouse, keyboard, monitor, and CPU, but these gadgets have been improvised with a lot of modifications.\n",
      "\n",
      "Nowadays, we have become very dependent on technology; therefore, it is difficult to imagine our lives without a computer. To learn any professional course, you must be well-versed in computer usage. Whether a school student or an employee, you must at least know the basics of computers. Along with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc. With the increasing usage and demands of people, computers have been developed and have made life easier. Starting from simple calculations to weather forecasting, computers have become a part of our lives.\n",
      "\n",
      "Text with Synonyms Replaced:\n",
      "< ! DOCTYPE hypertext_markup_language > < hypertext_markup_language > < head > < title > sample document < /title > < /head > < body > < h1 > welcome to text Preprocessing ! < /h1 > < phosphorus > text preprocessing involve assorted stairs such arsenic cleaning , tokenization , stem , and lemmatization. < /p > < phosphorus > data from different beginning might include hypertext_markup_language tag , special fictional_character like @ , # , & , and emojis üòä. < /p > < phosphorus > see this sample sentence : `` iodine calcium n't believe information_technology 's already 2023 ! text processing be amazing , be n't information_technology ? `` < /p > < phosphorus > besides , name_calling like Mayan , new haven , and company such arsenic apple are park entity inch texts. < /p > < phosphorus > misprint like this sentence need correction , and sol Department_of_Energy spelling. < /p > < /body > < /html > angstrom computer be one of the best man-made creation that hour_angle be develop to aid people inch assorted sector . information_technology hour_angle become such Associate_in_Nursing important part of our life that we discovery computer everywhere we go . start from our school life till our old age , we rich_person many use for computer . We rich_person become sol much dependant on computer that we are exploitation computer for about everything we bash . information_technology be angstrom device that can shop Associate_in_Nursing enormous sum of data inch information_technology . We are sol much dependant on computer that we bash not privation to put_option any pressure on ourselves . We blindly shop all our data inch angstrom computer with angstrom safety passcode . angstrom computer return up the duty and procedure the end_product inch no time , therefore devising our life easy . information_technology collect the data , procedure information_technology and then supply the final consequence to United_States inside angstrom very short time . people inch this day and age rich_person become sol reliant on computer that they can not imagine life without them . computer are significant because of their widespread use , productiveness , and openness . computer are the most necessitate invention due to their incredible benefit . computer are use inch every field , like the education sector , hospital , hotel , etc . If you go for angstrom Connecticut scan , X-ray , Oregon electrocardiogram , you volition need angstrom computer to check your body . inch case you privation to submit angstrom undertaking , you volition need angstrom computer . information_technology hour_angle become angstrom part of our life_style . The computer be angstrom remarkable piece of science that man hour_angle make to aid humanity . computer are inch charge of today ‚Äô second world , and they rich_person unquestionably change people ‚Äô second life_style and the condition of development state . inch the 21st century , information_technology be impossible to imagine angstrom life without angstrom computer and internet connection . The invention of computer hour_angle bring angstrom batch of change inch people ‚Äô second life and hour_angle help inch carry_through people ‚Äô second dream . angstrom computer be use inch assorted administration , school , institution , office , etc . information_technology can beryllium use to shop important information with high protection and can besides beryllium use to send and receive message , brand calculation , develop software , send and receive electronic_mail , etc . The major parts of angstrom computer are the mouse , keyboard , proctor , and central_processing_unit , merely these appliance rich_person be improvise with angstrom batch of alteration . present , we rich_person become very dependant on technology ; therefore , information_technology be difficult to imagine our life without angstrom computer . To learn any professional course , you must beryllium well-versed inch computer use . Whether angstrom school student Oregon Associate_in_Nursing employee , you must astatine least know the basics of computer . along with the increase use of computer , they rich_person be update inch many ways , like devising information_technology igniter to carry inch angstrom bag , devising processor fast , etc . With the increase use and demand of people , computer rich_person be develop and rich_person make life easy . start from simple calculation to weather prediction , computer rich_person become angstrom part of our life .\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources if not already present\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def get_most_common_synonym(token):\n",
    "    \"\"\"\n",
    "    Get the most common synonym for a token using WordNet.\n",
    "\n",
    "    Args:\n",
    "        token (str): The token to find synonyms for.\n",
    "\n",
    "    Returns:\n",
    "        str: The most common synonym or the original token if no synonym is found.\n",
    "    \"\"\"\n",
    "    synonyms = wordnet.synsets(token)\n",
    "    if not synonyms:\n",
    "        return token\n",
    "\n",
    "    # Get the most frequent lemma for the first synonym set\n",
    "    most_common_synonym = synonyms[0].lemmas()[0].name()\n",
    "\n",
    "    # Return the most common synonym if it's different from the token\n",
    "    if most_common_synonym != token and not most_common_synonym.isdigit():\n",
    "        return most_common_synonym\n",
    "    else:\n",
    "        return token\n",
    "\n",
    "def replace_synonyms(text):\n",
    "    \"\"\"\n",
    "    Replace synonyms in the input text with their most common synonym.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to process.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with synonyms replaced by their most common synonyms.\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    new_tokens = [get_most_common_synonym(token) if token.isalpha() else token for token in tokens]\n",
    "    return ' '.join(new_tokens)\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    # path to the sample text file\n",
    "    file_path = 'sample.txt'\n",
    "\n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "\n",
    "    # Replace synonyms in the text\n",
    "    replaced_text = replace_synonyms(text)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Original Text:\")\n",
    "    print(text)\n",
    "    print(\"\\nText with Synonyms Replaced:\")\n",
    "    print(replaced_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Back Translation\n",
    "The back translation code reads a text from a sample file, translates it from English to German, and then back to English using the Google Translate API. It prints the original text, the German translation, and the back-translated English text to compare differences. This process helps assess translation accuracy by revealing potential shifts in meaning during translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==4.0.0-rc1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.9.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
      "Original Text:\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Sample Document</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>Welcome to Text Preprocessing!</h1>\n",
      "    <p>Text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization.</p>\n",
      "    <p>Data from different sources might include HTML tags, special characters like @, #, &, and emojis üòä.</p>\n",
      "    <p>Consider this sample sentence: \"I can't believe it's already 2023! Text processing is awesome, isn't it?\"</p>\n",
      "    <p>Also, names like maya, New Haven, and companies such as apple are common entities in texts.</p>\n",
      "    <p>typos like this sentence need correction, and so does spelling.</p>\n",
      "  </body>\n",
      "</html>\n",
      "A computer is one of the best man-made creations that has been developed to help people in various sectors. It has become such an important part of our lives that we find computers everywhere we go. Starting from our school life till our old age, we have many uses for computers. We have become so much dependent on computers that we are using computers for almost everything we do. It is a device that can store an enormous amount of data in it. We are so much dependent on computers that we do not want to put any pressure on ourselves. We blindly store all our data in a computer with a safety passcode. A computer takes up the responsibility and processes the output in no time, hence making our life easier. It collects the data, processes it and then provides the final result to us within a very short time. People in this day and age have become so reliant on computers that they cannot imagine life without them. Computers are significant because of their widespread use, productivity, and openness. Computers are the most needed innovation due to their incredible benefits. Computers are used in every field, like the education sector, hospitals, hotels, etc. If you go for a CT Scan, X-ray, or ECG, you will need a computer to check your body. In case you want to submit a project, you will need a computer. It has become a part of our lifestyle.\n",
      "\n",
      "The computer is a remarkable piece of science that man has created to help humanity. Computers are in charge of today‚Äôs reality, and they have unquestionably altered people‚Äôs lifestyles and the condition of developing countries.\n",
      "\n",
      "In the 21st century, it is impossible to imagine a life without a computer and internet connection. The invention of computers has brought a lot of changes in people‚Äôs lives and has helped in fulfilling people‚Äôs dreams. A computer is used in various organisations, schools, institutions, offices, etc. It can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive emails, etc. The major parts of a computer are the mouse, keyboard, monitor, and CPU, but these gadgets have been improvised with a lot of modifications.\n",
      "\n",
      "Nowadays, we have become very dependent on technology; therefore, it is difficult to imagine our lives without a computer. To learn any professional course, you must be well-versed in computer usage. Whether a school student or an employee, you must at least know the basics of computers. Along with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc. With the increasing usage and demands of people, computers have been developed and have made life easier. Starting from simple calculations to weather forecasting, computers have become a part of our lives.\n",
      "\n",
      "German Translation:\n",
      "<! DocType html>\n",
      "<html>\n",
      "<kopf>\n",
      "<title> Beispieldokument </title>\n",
      "</head>\n",
      "<body>\n",
      "<h1> Willkommen bei der Vorbereitung des Textes! </h1>\n",
      "<p> Textvorverarbeitung beinhaltet verschiedene Schritte wie Reinigung, Tokenisierung, Stamm und Lemmatisierung. </p>\n",
      "<p> Daten aus verschiedenen Quellen k√∂nnen HTML -Tags, Sonderzeichen wie @, #& und Emojis üòä. </p> enthalten. </p>\n",
      "<p> Betrachten Sie diesen Beispielsatz: \"Ich kann nicht glauben, dass es bereits 2023 ist! Die Textverarbeitung ist gro√üartig, nicht wahr?\" </p>\n",
      "<p> Auch Namen wie Maya, New Haven und Unternehmen wie Apple sind gemeinsame Einheiten in Texten. </p>\n",
      "<p> Tippfehler wie dieser Satz ben√∂tigen Korrektur, ebenso wie Rechtschreibung. </p>\n",
      "</body>\n",
      "</html>\n",
      "Ein Computer ist eine der besten k√ºnstlichen Kreationen, die entwickelt wurden, um Menschen in verschiedenen Sektoren zu helfen.Es ist zu einem so wichtigen Teil unseres Lebens geworden, dass wir √ºberall Computer finden, wo wir hingehen.Ausgehend von unserem Schulleben bis zum Alter haben wir viele Verwendungszwecke f√ºr Computer.Wir sind so stark von Computern angewiesen, dass wir Computer f√ºr fast alles, was wir tun, verwenden.Es ist ein Ger√§t, das eine enorme Datenmenge darin speichern kann.Wir sind so stark von Computern angewiesen, dass wir keinen Druck auf uns selbst aus√ºben wollen.Wir speichern alle unsere Daten blind auf einem Computer mit einem Safety Passcode.Ein Computer √ºbernimmt die Verantwortung und verarbeitet die Ausgabe in k√ºrzester Zeit, wodurch unser Leben erleichtert wird.Es sammelt die Daten, verarbeitet sie und liefert uns dann das Endergebnis in sehr kurzer Zeit.Die Menschen in der heutigen Zeit sind so auf Computer angewiesen, dass sie sich das Leben ohne sie nicht vorstellen k√∂nnen.Computer sind aufgrund ihrer weit verbreiteten Verwendung, Produktivit√§t und Offenheit erheblich.Computer sind aufgrund ihrer unglaublichen Vorteile die dringendste Innovation.Computer werden in jedem Bereich wie im Bildungssektor, in Krankenh√§usern, Hotels usw. verwendet. Wenn Sie sich f√ºr einen CT-Scan, R√∂ntgen oder EKG entscheiden, ben√∂tigen Sie einen Computer, um Ihren K√∂rper zu √ºberpr√ºfen.Falls Sie ein Projekt einreichen m√∂chten, ben√∂tigen Sie einen Computer.Es ist ein Teil unseres Lebensstils geworden.\n",
      "\n",
      "Der Computer ist ein bemerkenswertes Wissenschaftsst√ºck, das der Mensch geschaffen hat, um der Menschheit zu helfen.Computer sind f√ºr die heutige Realit√§t verantwortlich und haben zweifellos den Lebensstil der Menschen und den Zustand der Entwicklungsl√§nder ver√§ndert.\n",
      "\n",
      "Im 21. Jahrhundert ist es unm√∂glich, sich ein Leben ohne Computer- und Internetverbindung vorzustellen.Die Erfindung von Computern hat viele Ver√§nderungen im Leben der Menschen vorgenommen und dazu beigetragen, die Tr√§ume der Menschen zu erf√ºllen.Ein Computer wird in verschiedenen Organisationen, Schulen, Institutionen, B√ºros usw. verwendet. Er kann verwendet werden, um wichtige Informationen mit hohem Schutz zu speichern, und kann auch zum Senden und Empfangen von Nachrichten, Berechnungen, Entwickeln von Software, Senden und Empfangen von E -Mails usw. verwendet werden..\n",
      "\n",
      "Heutzutage sind wir sehr von Technologie angewiesen.Daher ist es schwierig, sich unser Leben ohne Computer vorzustellen.Um einen professionellen Kurs zu erlernen, m√ºssen Sie mit der Computerverwendung vertraut sein.Egal, ob ein Sch√ºler oder ein Mitarbeiter, Sie m√ºssen zumindest die Grundlagen von Computern kennen.Zusammen mit der zunehmenden Verwendung von Computern wurden sie in vielerlei Hinsicht aktualisiert, z..Von einfachen Berechnungen bis hin zur Wettervorhersage sind Computer ein Teil unseres Lebens geworden.\n",
      "\n",
      "Back Translated Text:\n",
      "<!Doctype HTML>\n",
      "<html>\n",
      "<head>\n",
      "<title> sample document </title>\n",
      "</head>\n",
      "<body>\n",
      "<h1> Welcome to the preparation of the text!</h1>\n",
      "<p> Text preliminary processing includes various steps such as cleaning, tokenization, trunk and lemmatization.</p>\n",
      "<p> Data from different sources can be HTML tags, special characters like @, #& and emojis üòä.</p> included.</p>\n",
      "<p> Consider this example: \"I cannot believe that it is already in 2023! The word processing is great, isn't it?\"</p>\n",
      "<p> Also names like Maya, New Haven and companies like Apple are common units in texts.</p>\n",
      "<p> typing errors like this sentence require correction, as well as spelling.</p>\n",
      "</body>\n",
      "</hml>\n",
      "A computer is one of the best artificial creations that have been developed to help people in different sectors. It has become such an important part of our lives that we find computers wherever we go. Starting from our school life to ageWe many uses for computers. We are so instructed by computers that we use computers for almost everything we do. It is a device that can save an enormous amount of data in it. We are so dependent on computers that weDo not want to put pressure on ourselves. We store all of our data blindly on a computer with a Safety Passcode. A computer takes responsibility and processes the output in a very short time, which makes our lives easier.Then the end result in a very short time. The people of today are so dependent on computers that they cannot imagine life without them.Advantages The most urgent innovation.If you choose a CT scan, X-ray or EKG, you need a computer to check your body. If you want to submit a project, you need a computer. It has become part of our lifestyle.\n",
      "\n",
      "The computer is a remarkable piece of science that man has created to help humanity.\n",
      "\n",
      "In the 21st century it is impossible to imagine a life without a computer and internet connection. The invention of computers has made many changes in the life of people and contributed to fulfilling people's dreams.Used institutions, offices, etc.It can be used to save important information with high protection, and can also be used to send and receive messages, calculations, developing software, sending and receiving e -mails, etc.\n",
      "\n",
      "Nowadays we are very dependent on technology. It is difficult to imagine our life without a computer. To learn a professional course, you must be familiar with computer use, whether a student or an employee, you must at least the basis ofKnowing computers. Together with the increasing use of computers, they have been updated in many ways, for which simple calculations up to the weather forecast have become part of our lives.\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0-rc1\n",
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "\n",
    "# Initialize the Translator object\n",
    "translator = Translator()\n",
    "\n",
    "def back_translate(text):\n",
    "    \"\"\"\n",
    "    Perform back translation by translating the text to German\n",
    "    and then back to English.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to translate.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing the German translation and back-translated text.\n",
    "    \"\"\"\n",
    "    # Translate to German\n",
    "    german_translation = translator.translate(text, src='en', dest='de').text\n",
    "    \n",
    "    # Back-translate to English\n",
    "    back_to_english = translator.translate(german_translation, src='de', dest='en').text\n",
    "    \n",
    "    return german_translation, back_to_english\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "        \n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    # path to the sample text file\n",
    "    file_path = 'sample.txt'\n",
    "    \n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "    \n",
    "    # Perform back translation\n",
    "    german_translation, back_translated_text = back_translate(text)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Original Text:\")\n",
    "    print(text)\n",
    "    print(\"\\nGerman Translation:\")\n",
    "    print(german_translation)\n",
    "    print(\"\\nBack Translated Text:\")\n",
    "    print(back_translated_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Entity Replacement\n",
    "\n",
    "**Load spaCy Model**: The code initializes the spaCy English model (en_core_web_sm) for named entity recognition (NER).\n",
    "\n",
    "**Entity Replacement Function**: It defines a function (replace_entities) that scans the input text for named entities (e.g., people, organizations, locations) and replaces them with predefined placeholders like [PERSON], [ORGANIZATION], etc.\n",
    "\n",
    "**Load Text Data**: The code reads a sample text file into a pandas DataFrame, with each line treated as a review in a column named 'Review Content.'\n",
    "\n",
    "**Apply and Save**: It applies the entity replacement function to the 'Review Content' column, generates a new column with replaced entities, and saves the updated DataFrame to a new file. ew file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\mayal\\anaconda3\\lib\\site-packages (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "      --------------------------------------- 0.2/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "      --------------------------------------- 0.3/12.8 MB 2.0 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.4/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.5/12.8 MB 2.3 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.7/12.8 MB 2.4 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.8/12.8 MB 2.4 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.9/12.8 MB 2.3 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.0/12.8 MB 2.4 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.1/12.8 MB 2.3 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.3/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 2.4 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.1/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.2/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.3/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.3/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.5/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 2.6/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 2.7/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 2.8/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 3.0/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 3.1/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.2/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.0/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.1/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.2/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.2/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.3/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.3/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.4/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.4/12.8 MB 2.3 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.5/12.8 MB 2.3 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.5/12.8 MB 2.3 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.6/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.6/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.7/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.7/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.7/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.8/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 4.8/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 5.0/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 5.1/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 5.8/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 5.9/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 5.9/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 6.1/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 6.2/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 6.3/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 6.4/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.5/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.6/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.7/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.9/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.0/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 7.8/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 7.9/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 8.0/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 8.1/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 8.3/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 8.4/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 8.5/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.6/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.8/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.3/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.6/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.7/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.9/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 9.9/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.0/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.1/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.1/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.3/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.4/12.8 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.4/12.8 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.8/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.5/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.0)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "                                       Review Content  \\\n",
      "0                                     <!DOCTYPE html>   \n",
      "1                                              <html>   \n",
      "2                                              <head>   \n",
      "3                      <title>Sample Document</title>   \n",
      "4                                             </head>   \n",
      "5                                              <body>   \n",
      "6             <h1>Welcome to Text Preprocessing!</h1>   \n",
      "7       <p>Text preprocessing involves various ste...   \n",
      "8       <p>Data from different sources might inclu...   \n",
      "9       <p>Consider this sample sentence: \"I can't...   \n",
      "10      <p>Also, names like maya, New Haven, and c...   \n",
      "11      <p>typos like this sentence need correctio...   \n",
      "12                                            </body>   \n",
      "13                                            </html>   \n",
      "14  A computer is one of the best man-made creatio...   \n",
      "15  The computer is a remarkable piece of science ...   \n",
      "16  In the 21st century, it is impossible to imagi...   \n",
      "17  Nowadays, we have become very dependent on tec...   \n",
      "\n",
      "                Review Content with Entities Replaced  \n",
      "0                                     <!DOCTYPE html>  \n",
      "1                                              <html>  \n",
      "2                                              <head>  \n",
      "3                                     <title>[PERSON]  \n",
      "4                                             </head>  \n",
      "5                                              <body>  \n",
      "6             <h1>Welcome to Text Preprocessing!</h1>  \n",
      "7       <p>Text preprocessing involves various ste...  \n",
      "8       <p>Data from different sources might inclu...  \n",
      "9       <p>Consider this sample sentence: \"I can't...  \n",
      "10      <p>Also, names like maya, [LOCATION], and ...  \n",
      "11      <p>typos like this sentence need correctio...  \n",
      "12                                            </body>  \n",
      "13                                            </html>  \n",
      "14  A computer is one of the best man-made creatio...  \n",
      "15  The computer is a remarkable piece of science ...  \n",
      "16  In [DATE], it is impossible to imagine a life ...  \n",
      "17  Nowadays, we have become very dependent on tec...  \n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load spaCy's English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to replace named entities with placeholders\n",
    "def replace_entities(text):\n",
    "    \"\"\"\n",
    "    Replace named entities in the input text with placeholders.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to process.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with named entities replaced by placeholders.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    # Define placeholders for different types of entities\n",
    "    entity_placeholders = {\n",
    "        'PERSON': '[PERSON]',\n",
    "        'ORG': '[ORGANIZATION]',\n",
    "        'GPE': '[LOCATION]',\n",
    "        'DATE': '[DATE]',\n",
    "        'TIME': '[TIME]',\n",
    "        'MONEY': '[MONEY]',\n",
    "        'PERCENT': '[PERCENT]'\n",
    "    }\n",
    "\n",
    "    # Replace entities with placeholders\n",
    "    replaced_text = text\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in entity_placeholders:\n",
    "            placeholder = entity_placeholders[ent.label_]\n",
    "            replaced_text = replaced_text.replace(ent.text, placeholder)\n",
    "\n",
    "    return replaced_text\n",
    "\n",
    "# Load data from a sample text file\n",
    "def load_data_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Load text data from a file into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input text file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the text data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the text file into a DataFrame\n",
    "        df = pd.read_csv(file_path, sep='\\t', header=None, names=['Review Content'])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the file: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "file_path = 'sample.txt'  \n",
    "\n",
    "# Load the data from the file\n",
    "df = load_data_from_file(file_path)\n",
    "\n",
    "# Apply the entity replacement function to the DataFrame\n",
    "df['Review Content with Entities Replaced'] = df['Review Content'].apply(replace_entities)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df[['Review Content', 'Review Content with Entities Replaced']])\n",
    "\n",
    "# Optionally, save the updated DataFrame to a new file\n",
    "df.to_csv('processed_reviews.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Unicode Normalization\n",
    "**Unicode Normalization Function**: The code uses Python‚Äôs unicodedata.normalize() function to normalize text to a standard Unicode form (NFC - Canonical Composition).\n",
    "\n",
    "**Read Text File**: It defines a function (read_file) that opens and reads a text file in UTF-8 encoding, returning the content as a string.\n",
    "\n",
    "**Normalize Text**: In the main() function, it reads the text from the sample file and applies the Unicode normalization function to standardize any Unicode characters.\n",
    "\n",
    "**Print Output**: Finally, the code prints both the original and normalized versions of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " <!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Sample Document</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>Welcome to Text Preprocessing!</h1>\n",
      "    <p>Text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization.</p>\n",
      "    <p>Data from different sources might include HTML tags, special characters like @, #, &, and emojis üòä.</p>\n",
      "    <p>Consider this sample sentence: \"I can't believe it's already 2023! Text processing is awesome, isn't it?\"</p>\n",
      "    <p>Also, names like maya, New Haven, and companies such as apple are common entities in texts.</p>\n",
      "    <p>typos like this sentence need correction, and so does spelling.</p>\n",
      "  </body>\n",
      "</html>\n",
      "A computer is one of the best man-made creations that has been developed to help people in various sectors. It has become such an important part of our lives that we find computers everywhere we go. Starting from our school life till our old age, we have many uses for computers. We have become so much dependent on computers that we are using computers for almost everything we do. It is a device that can store an enormous amount of data in it. We are so much dependent on computers that we do not want to put any pressure on ourselves. We blindly store all our data in a computer with a safety passcode. A computer takes up the responsibility and processes the output in no time, hence making our life easier. It collects the data, processes it and then provides the final result to us within a very short time. People in this day and age have become so reliant on computers that they cannot imagine life without them. Computers are significant because of their widespread use, productivity, and openness. Computers are the most needed innovation due to their incredible benefits. Computers are used in every field, like the education sector, hospitals, hotels, etc. If you go for a CT Scan, X-ray, or ECG, you will need a computer to check your body. In case you want to submit a project, you will need a computer. It has become a part of our lifestyle.\n",
      "\n",
      "The computer is a remarkable piece of science that man has created to help humanity. Computers are in charge of today‚Äôs reality, and they have unquestionably altered people‚Äôs lifestyles and the condition of developing countries.\n",
      "\n",
      "In the 21st century, it is impossible to imagine a life without a computer and internet connection. The invention of computers has brought a lot of changes in people‚Äôs lives and has helped in fulfilling people‚Äôs dreams. A computer is used in various organisations, schools, institutions, offices, etc. It can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive emails, etc. The major parts of a computer are the mouse, keyboard, monitor, and CPU, but these gadgets have been improvised with a lot of modifications.\n",
      "\n",
      "Nowadays, we have become very dependent on technology; therefore, it is difficult to imagine our lives without a computer. To learn any professional course, you must be well-versed in computer usage. Whether a school student or an employee, you must at least know the basics of computers. Along with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc. With the increasing usage and demands of people, computers have been developed and have made life easier. Starting from simple calculations to weather forecasting, computers have become a part of our lives.\n",
      "\n",
      "Normalized Text:\n",
      " <!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Sample Document</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>Welcome to Text Preprocessing!</h1>\n",
      "    <p>Text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization.</p>\n",
      "    <p>Data from different sources might include HTML tags, special characters like @, #, &, and emojis üòä.</p>\n",
      "    <p>Consider this sample sentence: \"I can't believe it's already 2023! Text processing is awesome, isn't it?\"</p>\n",
      "    <p>Also, names like maya, New Haven, and companies such as apple are common entities in texts.</p>\n",
      "    <p>typos like this sentence need correction, and so does spelling.</p>\n",
      "  </body>\n",
      "</html>\n",
      "A computer is one of the best man-made creations that has been developed to help people in various sectors. It has become such an important part of our lives that we find computers everywhere we go. Starting from our school life till our old age, we have many uses for computers. We have become so much dependent on computers that we are using computers for almost everything we do. It is a device that can store an enormous amount of data in it. We are so much dependent on computers that we do not want to put any pressure on ourselves. We blindly store all our data in a computer with a safety passcode. A computer takes up the responsibility and processes the output in no time, hence making our life easier. It collects the data, processes it and then provides the final result to us within a very short time. People in this day and age have become so reliant on computers that they cannot imagine life without them. Computers are significant because of their widespread use, productivity, and openness. Computers are the most needed innovation due to their incredible benefits. Computers are used in every field, like the education sector, hospitals, hotels, etc. If you go for a CT Scan, X-ray, or ECG, you will need a computer to check your body. In case you want to submit a project, you will need a computer. It has become a part of our lifestyle.\n",
      "\n",
      "The computer is a remarkable piece of science that man has created to help humanity. Computers are in charge of today‚Äôs reality, and they have unquestionably altered people‚Äôs lifestyles and the condition of developing countries.\n",
      "\n",
      "In the 21st century, it is impossible to imagine a life without a computer and internet connection. The invention of computers has brought a lot of changes in people‚Äôs lives and has helped in fulfilling people‚Äôs dreams. A computer is used in various organisations, schools, institutions, offices, etc. It can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive emails, etc. The major parts of a computer are the mouse, keyboard, monitor, and CPU, but these gadgets have been improvised with a lot of modifications.\n",
      "\n",
      "Nowadays, we have become very dependent on technology; therefore, it is difficult to imagine our lives without a computer. To learn any professional course, you must be well-versed in computer usage. Whether a school student or an employee, you must at least know the basics of computers. Along with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc. With the increasing usage and demands of people, computers have been developed and have made life easier. Starting from simple calculations to weather forecasting, computers have become a part of our lives.\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    \"\"\"\n",
    "    Normalize Unicode characters in the input text to a standard form.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to normalize.\n",
    "\n",
    "    Returns:\n",
    "        str: The Unicode-normalized text.\n",
    "    \"\"\"\n",
    "    # Normalize the text to NFC (Normalization Form C)\n",
    "    normalized_text = unicodedata.normalize('NFC', text)\n",
    "    return normalized_text\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    # path to your sample text file\n",
    "    file_path = 'sample.txt'\n",
    "    \n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "    \n",
    "    # Normalize the text\n",
    "    normalized_text = normalize_unicode(text)\n",
    "    \n",
    "    # Print the original and normalized text\n",
    "    print(\"Original Text:\\n\", text)\n",
    "    print(\"\\nNormalized Text:\\n\", normalized_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Spell Correction\n",
    "Spell correction is the process of identifying and fixing misspelled words in a text, ensuring that the text is accurate and readable.\n",
    "\n",
    "**Install and Import Packages**: The code installs and imports the TextBlob library, which is used for natural language processing tasks like spell correction.\n",
    "\n",
    "**Define Spell Correction Function**: The correct_spelling function creates a TextBlob object from the input text and uses its correct() method to automatically correct spelling mistakes.\n",
    "\n",
    "**Read Text File**: The read_file function reads the content of a text file, assuming it is encoded in UTF-8, and returns it as a string.\n",
    "\n",
    "**Apply Spell Correction**: In the main() function, the code reads text from a specified file, applies the spell correction function, and prints the corrected text.\n",
    "\n",
    "**Execution**: The main() function is executed if the script is run directly, displaying the corrected text to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\mayal\\anaconda3\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corrected Text:\n",
      " <!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Ample Document</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <he>Welcome to Next Preprocessing!</he>\n",
      "    <p>Next preprocessing involves various steps such as cleaning, tokenization, steaming, and lemmatization.</p>\n",
      "    <p>Data from different sources might include HTML tags, special characters like @, #, &, and femoris üòä.</p>\n",
      "    <p>Consider this sample sentence: \"I can't believe it's already 2023! Next processing is awesome, isn't it?\"</p>\n",
      "    <p>Also, names like may, New Haven, and companies such as apple are common entitles in texts.</p>\n",
      "    <p>types like this sentence need correction, and so does spelling.</p>\n",
      "  </body>\n",
      "</html>\n",
      "A computer is one of the best man-made creation that has been developed to help people in various sector. It has become such an important part of our lives that we find computers everywhere we go. Starting from our school life till our old age, we have many uses for computers. He have become so much dependent on computers that we are using computers for almost everything we do. It is a device that can store an enormous amount of data in it. He are so much dependent on computers that we do not want to put any pressure on ourselves. He blandly store all our data in a computer with a safety passcode. A computer takes up the responsibility and processes the output in no time, hence making our life easier. It collects the data, processes it and then provides the final result to us within a very short time. People in this day and age have become so radiant on computers that they cannot imagine life without them. Computers are significant because of their widespread use, productivity, and openness. Computers are the most needed innovation due to their incredible benefits. Computers are used in every field, like the education sector, hospitals, hotels, etc. Of you go for a of Can, X-ray, or ECG, you will need a computer to check your body. In case you want to submit a project, you will need a computer. It has become a part of our lifestyle.\n",
      "\n",
      "The computer is a remarkable piece of science that man has created to help humanity. Computers are in charge of today‚Äôs reality, and they have unquestionably altered people‚Äôs lifestyle and the condition of developing countries.\n",
      "\n",
      "In the must century, it is impossible to imagine a life without a computer and internet connection. The invention of computers has brought a lot of changes in people‚Äôs lives and has helped in fulfilling people‚Äôs dreams. A computer is used in various organizations, schools, institutions, offices, etc. It can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive email, etc. The major parts of a computer are the mouse, keyboard, monitor, and CPU, but these badges have been improvised with a lot of modifications.\n",
      "\n",
      "Nowadays, we have become very dependent on technology; therefore, it is difficult to imagine our lives without a computer. To learn any professional course, you must be well-versed in computer usage. Whether a school student or an employee, you must at least know the basis of computers. Long with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc. With the increasing usage and demands of people, computers have been developed and have made life easier. Starting from simple calculations to weather forecasting, computers have become a part of our lives.\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!python -m textblob.download_corpora\n",
    "\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "def correct_spelling(text):\n",
    "    \"\"\"\n",
    "    Correct spelling mistakes in the input text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text with possible spelling mistakes.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with corrected spelling.\n",
    "    \"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    corrected_text = blob.correct()\n",
    "    return str(corrected_text)\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    # Define the path to your sample text file\n",
    "    file_path = 'sample.txt'\n",
    "    \n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "    \n",
    "    # Correct spelling in the text\n",
    "    corrected_text = correct_spelling(text)\n",
    "    \n",
    "    \n",
    "    print(\"\\nCorrected Text:\\n\", corrected_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7: Sentence Segmentation\n",
    "Sentence segmentation is the process of dividing a text into individual sentences, which helps in structuring and analyzing the text at the sentence level.\n",
    "\n",
    "**Install and Import Packages**: The code installs and imports the nltk library and its sentence tokenizer sent_tokenize from the punkt package, which is necessary for sentence segmentation.\n",
    "\n",
    "**Define Sentence Segmentation Function**: The segment_sentences function uses sent_tokenize to split the input text into a list of sentences.\n",
    "\n",
    "**Read Text File**: The read_file function reads the content from a text file using UTF-8 encoding and returns it as a string.\n",
    "\n",
    "**Segment and Print Sentences**: In the main() function, the script reads the text from the file, segments it into sentences, and prints each sentence with its index.\n",
    "\n",
    "**Execution**: If the script is run directly, the main() function executes, showing the segmented sentences to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mayal\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mayal\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented Sentences:\n",
      "Sentence 1: <!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Sample Document</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>Welcome to Text Preprocessing!</h1>\n",
      "    <p>Text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization.</p>\n",
      "    <p>Data from different sources might include HTML tags, special characters like @, #, &, and emojis üòä.</p>\n",
      "    <p>Consider this sample sentence: \"I can't believe it's already 2023!\n",
      "Sentence 2: Text processing is awesome, isn't it?\n",
      "Sentence 3: \"</p>\n",
      "    <p>Also, names like maya, New Haven, and companies such as apple are common entities in texts.</p>\n",
      "    <p>typos like this sentence need correction, and so does spelling.</p>\n",
      "  </body>\n",
      "</html>\n",
      "A computer is one of the best man-made creations that has been developed to help people in various sectors.\n",
      "Sentence 4: It has become such an important part of our lives that we find computers everywhere we go.\n",
      "Sentence 5: Starting from our school life till our old age, we have many uses for computers.\n",
      "Sentence 6: We have become so much dependent on computers that we are using computers for almost everything we do.\n",
      "Sentence 7: It is a device that can store an enormous amount of data in it.\n",
      "Sentence 8: We are so much dependent on computers that we do not want to put any pressure on ourselves.\n",
      "Sentence 9: We blindly store all our data in a computer with a safety passcode.\n",
      "Sentence 10: A computer takes up the responsibility and processes the output in no time, hence making our life easier.\n",
      "Sentence 11: It collects the data, processes it and then provides the final result to us within a very short time.\n",
      "Sentence 12: People in this day and age have become so reliant on computers that they cannot imagine life without them.\n",
      "Sentence 13: Computers are significant because of their widespread use, productivity, and openness.\n",
      "Sentence 14: Computers are the most needed innovation due to their incredible benefits.\n",
      "Sentence 15: Computers are used in every field, like the education sector, hospitals, hotels, etc.\n",
      "Sentence 16: If you go for a CT Scan, X-ray, or ECG, you will need a computer to check your body.\n",
      "Sentence 17: In case you want to submit a project, you will need a computer.\n",
      "Sentence 18: It has become a part of our lifestyle.\n",
      "Sentence 19: The computer is a remarkable piece of science that man has created to help humanity.\n",
      "Sentence 20: Computers are in charge of today‚Äôs reality, and they have unquestionably altered people‚Äôs lifestyles and the condition of developing countries.\n",
      "Sentence 21: In the 21st century, it is impossible to imagine a life without a computer and internet connection.\n",
      "Sentence 22: The invention of computers has brought a lot of changes in people‚Äôs lives and has helped in fulfilling people‚Äôs dreams.\n",
      "Sentence 23: A computer is used in various organisations, schools, institutions, offices, etc.\n",
      "Sentence 24: It can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive emails, etc.\n",
      "Sentence 25: The major parts of a computer are the mouse, keyboard, monitor, and CPU, but these gadgets have been improvised with a lot of modifications.\n",
      "Sentence 26: Nowadays, we have become very dependent on technology; therefore, it is difficult to imagine our lives without a computer.\n",
      "Sentence 27: To learn any professional course, you must be well-versed in computer usage.\n",
      "Sentence 28: Whether a school student or an employee, you must at least know the basics of computers.\n",
      "Sentence 29: Along with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc.\n",
      "Sentence 30: With the increasing usage and demands of people, computers have been developed and have made life easier.\n",
      "Sentence 31: Starting from simple calculations to weather forecasting, computers have become a part of our lives.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!python -m nltk.downloader punkt\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Ensure NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "def segment_sentences(text):\n",
    "    \"\"\"\n",
    "    Segment the input text into individual sentences.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be segmented.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of sentences.\n",
    "    \"\"\"\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    # Define the path to your sample text file\n",
    "    file_path = 'sample.txt'\n",
    "    \n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "    \n",
    "    # Segment the text into sentences\n",
    "    sentences = segment_sentences(text)\n",
    "    \n",
    "    # Print each sentence\n",
    "    print(\"Segmented Sentences:\")\n",
    "    for i, sentence in enumerate(sentences, 1):\n",
    "        print(f\"Sentence {i}: {sentence}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8: Word Tokenization\n",
    "Word tokenization is the process of splitting a text into its constituent words or tokens, which helps in analyzing and processing text data at the word level.\n",
    "\n",
    "**Import and Download Packages**: The code imports the word_tokenize function from nltk and ensures that the necessary punkt tokenizer models are downloaded.\n",
    "\n",
    "**Define Tokenization Function**: The tokenize_words function uses word_tokenize to break the input text into a list of individual words.\n",
    "\n",
    "**Read Text File**: The read_file function opens and reads the content of a text file specified by file_path, returning the content as a string.\n",
    "\n",
    "**Tokenize and Print**: In the main() function, the script reads the text from the file, tokenizes it into words, and prints the resulting list of words.\n",
    "\n",
    "**Execution**: If executed directly, the main() function will run, displaying the tokenized words from the sample text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Words:\n",
      "['<', '!', 'DOCTYPE', 'html', '>', '<', 'html', '>', '<', 'head', '>', '<', 'title', '>', 'Sample', 'Document', '<', '/title', '>', '<', '/head', '>', '<', 'body', '>', '<', 'h1', '>', 'Welcome', 'to', 'Text', 'Preprocessing', '!', '<', '/h1', '>', '<', 'p', '>', 'Text', 'preprocessing', 'involves', 'various', 'steps', 'such', 'as', 'cleaning', ',', 'tokenization', ',', 'stemming', ',', 'and', 'lemmatization.', '<', '/p', '>', '<', 'p', '>', 'Data', 'from', 'different', 'sources', 'might', 'include', 'HTML', 'tags', ',', 'special', 'characters', 'like', '@', ',', '#', ',', '&', ',', 'and', 'emojis', 'üòä.', '<', '/p', '>', '<', 'p', '>', 'Consider', 'this', 'sample', 'sentence', ':', '``', 'I', 'ca', \"n't\", 'believe', 'it', \"'s\", 'already', '2023', '!', 'Text', 'processing', 'is', 'awesome', ',', 'is', \"n't\", 'it', '?', '``', '<', '/p', '>', '<', 'p', '>', 'Also', ',', 'names', 'like', 'maya', ',', 'New', 'Haven', ',', 'and', 'companies', 'such', 'as', 'apple', 'are', 'common', 'entities', 'in', 'texts.', '<', '/p', '>', '<', 'p', '>', 'typos', 'like', 'this', 'sentence', 'need', 'correction', ',', 'and', 'so', 'does', 'spelling.', '<', '/p', '>', '<', '/body', '>', '<', '/html', '>', 'A', 'computer', 'is', 'one', 'of', 'the', 'best', 'man-made', 'creations', 'that', 'has', 'been', 'developed', 'to', 'help', 'people', 'in', 'various', 'sectors', '.', 'It', 'has', 'become', 'such', 'an', 'important', 'part', 'of', 'our', 'lives', 'that', 'we', 'find', 'computers', 'everywhere', 'we', 'go', '.', 'Starting', 'from', 'our', 'school', 'life', 'till', 'our', 'old', 'age', ',', 'we', 'have', 'many', 'uses', 'for', 'computers', '.', 'We', 'have', 'become', 'so', 'much', 'dependent', 'on', 'computers', 'that', 'we', 'are', 'using', 'computers', 'for', 'almost', 'everything', 'we', 'do', '.', 'It', 'is', 'a', 'device', 'that', 'can', 'store', 'an', 'enormous', 'amount', 'of', 'data', 'in', 'it', '.', 'We', 'are', 'so', 'much', 'dependent', 'on', 'computers', 'that', 'we', 'do', 'not', 'want', 'to', 'put', 'any', 'pressure', 'on', 'ourselves', '.', 'We', 'blindly', 'store', 'all', 'our', 'data', 'in', 'a', 'computer', 'with', 'a', 'safety', 'passcode', '.', 'A', 'computer', 'takes', 'up', 'the', 'responsibility', 'and', 'processes', 'the', 'output', 'in', 'no', 'time', ',', 'hence', 'making', 'our', 'life', 'easier', '.', 'It', 'collects', 'the', 'data', ',', 'processes', 'it', 'and', 'then', 'provides', 'the', 'final', 'result', 'to', 'us', 'within', 'a', 'very', 'short', 'time', '.', 'People', 'in', 'this', 'day', 'and', 'age', 'have', 'become', 'so', 'reliant', 'on', 'computers', 'that', 'they', 'can', 'not', 'imagine', 'life', 'without', 'them', '.', 'Computers', 'are', 'significant', 'because', 'of', 'their', 'widespread', 'use', ',', 'productivity', ',', 'and', 'openness', '.', 'Computers', 'are', 'the', 'most', 'needed', 'innovation', 'due', 'to', 'their', 'incredible', 'benefits', '.', 'Computers', 'are', 'used', 'in', 'every', 'field', ',', 'like', 'the', 'education', 'sector', ',', 'hospitals', ',', 'hotels', ',', 'etc', '.', 'If', 'you', 'go', 'for', 'a', 'CT', 'Scan', ',', 'X-ray', ',', 'or', 'ECG', ',', 'you', 'will', 'need', 'a', 'computer', 'to', 'check', 'your', 'body', '.', 'In', 'case', 'you', 'want', 'to', 'submit', 'a', 'project', ',', 'you', 'will', 'need', 'a', 'computer', '.', 'It', 'has', 'become', 'a', 'part', 'of', 'our', 'lifestyle', '.', 'The', 'computer', 'is', 'a', 'remarkable', 'piece', 'of', 'science', 'that', 'man', 'has', 'created', 'to', 'help', 'humanity', '.', 'Computers', 'are', 'in', 'charge', 'of', 'today', '‚Äô', 's', 'reality', ',', 'and', 'they', 'have', 'unquestionably', 'altered', 'people', '‚Äô', 's', 'lifestyles', 'and', 'the', 'condition', 'of', 'developing', 'countries', '.', 'In', 'the', '21st', 'century', ',', 'it', 'is', 'impossible', 'to', 'imagine', 'a', 'life', 'without', 'a', 'computer', 'and', 'internet', 'connection', '.', 'The', 'invention', 'of', 'computers', 'has', 'brought', 'a', 'lot', 'of', 'changes', 'in', 'people', '‚Äô', 's', 'lives', 'and', 'has', 'helped', 'in', 'fulfilling', 'people', '‚Äô', 's', 'dreams', '.', 'A', 'computer', 'is', 'used', 'in', 'various', 'organisations', ',', 'schools', ',', 'institutions', ',', 'offices', ',', 'etc', '.', 'It', 'can', 'be', 'used', 'to', 'store', 'important', 'information', 'with', 'high', 'protection', 'and', 'can', 'also', 'be', 'used', 'to', 'send', 'and', 'receive', 'messages', ',', 'make', 'calculations', ',', 'develop', 'software', ',', 'send', 'and', 'receive', 'emails', ',', 'etc', '.', 'The', 'major', 'parts', 'of', 'a', 'computer', 'are', 'the', 'mouse', ',', 'keyboard', ',', 'monitor', ',', 'and', 'CPU', ',', 'but', 'these', 'gadgets', 'have', 'been', 'improvised', 'with', 'a', 'lot', 'of', 'modifications', '.', 'Nowadays', ',', 'we', 'have', 'become', 'very', 'dependent', 'on', 'technology', ';', 'therefore', ',', 'it', 'is', 'difficult', 'to', 'imagine', 'our', 'lives', 'without', 'a', 'computer', '.', 'To', 'learn', 'any', 'professional', 'course', ',', 'you', 'must', 'be', 'well-versed', 'in', 'computer', 'usage', '.', 'Whether', 'a', 'school', 'student', 'or', 'an', 'employee', ',', 'you', 'must', 'at', 'least', 'know', 'the', 'basics', 'of', 'computers', '.', 'Along', 'with', 'the', 'increasing', 'usage', 'of', 'computers', ',', 'they', 'have', 'been', 'updated', 'in', 'many', 'ways', ',', 'like', 'making', 'it', 'lighter', 'to', 'carry', 'in', 'a', 'bag', ',', 'making', 'processors', 'faster', ',', 'etc', '.', 'With', 'the', 'increasing', 'usage', 'and', 'demands', 'of', 'people', ',', 'computers', 'have', 'been', 'developed', 'and', 'have', 'made', 'life', 'easier', '.', 'Starting', 'from', 'simple', 'calculations', 'to', 'weather', 'forecasting', ',', 'computers', 'have', 'become', 'a', 'part', 'of', 'our', 'lives', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize_words(text):\n",
    "    \"\"\"\n",
    "    Tokenize the input text into individual words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of words.\n",
    "    \"\"\"\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    # Define the path to your sample text file\n",
    "    file_path = 'sample.txt'\n",
    "    \n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = tokenize_words(text)\n",
    "    \n",
    "    # Print the tokenized words\n",
    "    print(\"Tokenized Words:\")\n",
    "    print(words)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9: Stop-Word Removal\n",
    "Stop word removal is the process of filtering out common words (such as \"and,\" \"the,\" \"is\") from a text, which are considered less informative and can be safely ignored in text analysis.\n",
    "\n",
    "**Import and Download Packages**: The code imports stopwords and word_tokenize from nltk, and ensures the necessary datasets are downloaded.\n",
    "\n",
    "**Define Stop Word Removal Function**: The remove_stop_words function tokenizes the input text into words, filters out common stop words, and then reconstructs the text from the remaining words.\n",
    "\n",
    "**Read Text File**: The read_file function reads and returns the content of a specified text file.\n",
    "\n",
    "**Process and Print**: In the main() function, the script reads the text from the file, removes stop words, and prints the cleaned text.\n",
    "\n",
    "**Execution**: Running the main() function will display the text from the sample file with stop words removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text After Stop Word Removal:\n",
      "< ! DOCTYPE html > < html > < head > < title > Sample Document < /title > < /head > < body > < h1 > Welcome Text Preprocessing ! < /h1 > < p > Text preprocessing involves various steps cleaning , tokenization , stemming , lemmatization. < /p > < p > Data different sources might include HTML tags , special characters like @ , # , & , emojis üòä. < /p > < p > Consider sample sentence : `` ca n't believe 's already 2023 ! Text processing awesome , n't ? `` < /p > < p > Also , names like maya , New , companies apple common entities texts. < /p > < p > typos like sentence need correction , spelling. < /p > < /body > < /html > computer one best man-made creations developed help people various sectors . become important part lives find computers everywhere go . Starting school life till old age , many uses computers . become much dependent computers using computers almost everything . device store enormous amount data . much dependent computers want put pressure . blindly store data computer safety passcode . computer takes responsibility processes output time , hence making life easier . collects data , processes provides final result us within short time . People day age become reliant computers imagine life without . Computers significant widespread use , productivity , openness . Computers needed innovation due incredible benefits . Computers used every field , like education sector , hospitals , hotels , etc . go CT Scan , X-ray , ECG , need computer check body . case want submit project , need computer . become part lifestyle . computer remarkable piece science man created help humanity . Computers charge today ‚Äô reality , unquestionably altered people ‚Äô lifestyles condition developing countries . 21st century , impossible imagine life without computer internet connection . invention computers brought lot changes people ‚Äô lives helped fulfilling people ‚Äô dreams . computer used various organisations , schools , institutions , offices , etc . used store important information high protection also used send receive messages , make calculations , develop software , send receive emails , etc . major parts computer mouse , keyboard , monitor , CPU , gadgets improvised lot modifications . Nowadays , become dependent technology ; therefore , difficult imagine lives without computer . learn professional course , must well-versed computer usage . Whether school student employee , must least know basics computers . Along increasing usage computers , updated many ways , like making lighter carry bag , making processors faster , etc . increasing usage demands people , computers developed made life easier . Starting simple calculations weather forecasting , computers become part lives .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure NLTK data is downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"\n",
    "    Remove stop words from the input text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be processed.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with stop words removed.\n",
    "    \"\"\"\n",
    "    # Load the list of stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Reconstruct the text from the filtered words\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    # Define the path to your sample text file\n",
    "    file_path = 'sample.txt'\n",
    "    \n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "    \n",
    "    # Remove stop words from the text\n",
    "    cleaned_text = remove_stop_words(text)\n",
    "    \n",
    "    # Print the cleaned text\n",
    "    print(\"Text After Stop Word Removal:\")\n",
    "    print(cleaned_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10: Normalization\n",
    "Normalization is the process of transforming text into a standard format by converting it to lowercase, removing extra spaces, and standardizing punctuation to ensure consistent and comparable text data.\n",
    "\n",
    "**Convert to Lowercase**: The normalize_text function begins by converting all characters in the text to lowercase to standardize the case.\n",
    "\n",
    "**Remove Extra Whitespace**: It then removes any extra whitespace by splitting the text into words and joining them back together with a single space.\n",
    "\n",
    "**Standardize Punctuation**: The function uses regular expressions to adjust punctuation‚Äîspecifically, it removes spaces before punctuation and optionally ensures a space follows punctuation marks.\n",
    "\n",
    "**Read and Process Text**: The main() function reads text from a specified file, applies the normalization function, and prints the normalized result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Text:\n",
      "< !doctype html> <html> <head> <title>sample document</title> </head> <body> <h1>welcome to text preprocessing !</h1> <p>text preprocessing involves various steps such as cleaning, tokenization, stemming, and lemmatization .</p> <p>data from different sources might include html tags, special characters like @, #, &, and emojis üòä .</p> <p>consider this sample sentence:\"i can't believe it's already 2023 ! text processing is awesome, isn't it ?\"</p> <p>also, names like maya, new haven, and companies such as apple are common entities in texts .</p> <p>typos like this sentence need correction, and so does spelling .</p> </body> </html> a computer is one of the best man-made creations that has been developed to help people in various sectors . it has become such an important part of our lives that we find computers everywhere we go . starting from our school life till our old age, we have many uses for computers . we have become so much dependent on computers that we are using computers for almost everything we do . it is a device that can store an enormous amount of data in it . we are so much dependent on computers that we do not want to put any pressure on ourselves . we blindly store all our data in a computer with a safety passcode . a computer takes up the responsibility and processes the output in no time, hence making our life easier . it collects the data, processes it and then provides the final result to us within a very short time . people in this day and age have become so reliant on computers that they cannot imagine life without them . computers are significant because of their widespread use, productivity, and openness . computers are the most needed innovation due to their incredible benefits . computers are used in every field, like the education sector, hospitals, hotels, etc . if you go for a ct scan, x-ray, or ecg, you will need a computer to check your body . in case you want to submit a project, you will need a computer . it has become a part of our lifestyle . the computer is a remarkable piece of science that man has created to help humanity . computers are in charge of today‚Äôs reality, and they have unquestionably altered people‚Äôs lifestyles and the condition of developing countries . in the 21st century, it is impossible to imagine a life without a computer and internet connection . the invention of computers has brought a lot of changes in people‚Äôs lives and has helped in fulfilling people‚Äôs dreams . a computer is used in various organisations, schools, institutions, offices, etc . it can be used to store important information with high protection and can also be used to send and receive messages, make calculations, develop software, send and receive emails, etc . the major parts of a computer are the mouse, keyboard, monitor, and cpu, but these gadgets have been improvised with a lot of modifications . nowadays, we have become very dependent on technology; therefore, it is difficult to imagine our lives without a computer . to learn any professional course, you must be well-versed in computer usage . whether a school student or an employee, you must at least know the basics of computers . along with the increasing usage of computers, they have been updated in many ways, like making it lighter to carry in a bag, making processors faster, etc . with the increasing usage and demands of people, computers have been developed and have made life easier . starting from simple calculations to weather forecasting, computers have become a part of our lives .\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalize the input text by converting it to lowercase,\n",
    "    removing extra whitespace, and standardizing punctuation.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to normalize.\n",
    "\n",
    "    Returns:\n",
    "        str: The normalized text.\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Standardize punctuation (optional, depending on your needs)\n",
    "    text = re.sub(r'\\s([?.!\"])', r'\\1', text)  # Remove space before punctuation\n",
    "    text = re.sub(r'([?.!])', r' \\1', text)   # Add space after punctuation if needed\n",
    "    \n",
    "    return text\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    # Define the path to your sample text file\n",
    "    file_path = 'sample.txt'\n",
    "    \n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "    \n",
    "    # Normalize the text\n",
    "    normalized_text = normalize_text(text)\n",
    "    \n",
    "    # Print the normalized text\n",
    "    print(\"Normalized Text:\")\n",
    "    print(normalized_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11: Stemming\n",
    "Stemming is a text processing technique that reduces words to their root or base form by stripping suffixes and prefixes, which helps in standardizing text for analysis and comparison.\n",
    "\n",
    "**Tokenization**: The stem_text function first tokenizes the input text into individual words using word_tokenize.\n",
    "\n",
    "**Stemming**: It then applies stemming to each word using the Porter Stemmer, reducing words to their root forms.\n",
    "\n",
    "**Reconstruction**: The stemmed words are joined back into a single string to form the processed text.\n",
    "\n",
    "**File Processing**: In the main() function, the code reads text from a file, applies the stemming function, and prints the stemmed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Text:\n",
      "< ! doctyp html > < html > < head > < titl > sampl document < /titl > < /head > < bodi > < h1 > welcom to text preprocess ! < /h1 > < p > text preprocess involv variou step such as clean , token , stem , and lemmatization. < /p > < p > data from differ sourc might includ html tag , special charact like @ , # , & , and emoji üòä. < /p > < p > consid thi sampl sentenc : `` i ca n't believ it 's alreadi 2023 ! text process is awesom , is n't it ? `` < /p > < p > also , name like maya , new haven , and compani such as appl are common entiti in texts. < /p > < p > typo like thi sentenc need correct , and so doe spelling. < /p > < /bodi > < /html > a comput is one of the best man-mad creation that ha been develop to help peopl in variou sector . it ha becom such an import part of our live that we find comput everywher we go . start from our school life till our old age , we have mani use for comput . we have becom so much depend on comput that we are use comput for almost everyth we do . it is a devic that can store an enorm amount of data in it . we are so much depend on comput that we do not want to put ani pressur on ourselv . we blindli store all our data in a comput with a safeti passcod . a comput take up the respons and process the output in no time , henc make our life easier . it collect the data , process it and then provid the final result to us within a veri short time . peopl in thi day and age have becom so reliant on comput that they can not imagin life without them . comput are signific becaus of their widespread use , product , and open . comput are the most need innov due to their incred benefit . comput are use in everi field , like the educ sector , hospit , hotel , etc . if you go for a ct scan , x-ray , or ecg , you will need a comput to check your bodi . in case you want to submit a project , you will need a comput . it ha becom a part of our lifestyl . the comput is a remark piec of scienc that man ha creat to help human . comput are in charg of today ‚Äô s realiti , and they have unquestion alter peopl ‚Äô s lifestyl and the condit of develop countri . in the 21st centuri , it is imposs to imagin a life without a comput and internet connect . the invent of comput ha brought a lot of chang in peopl ‚Äô s live and ha help in fulfil peopl ‚Äô s dream . a comput is use in variou organis , school , institut , offic , etc . it can be use to store import inform with high protect and can also be use to send and receiv messag , make calcul , develop softwar , send and receiv email , etc . the major part of a comput are the mous , keyboard , monitor , and cpu , but these gadget have been improvis with a lot of modif . nowaday , we have becom veri depend on technolog ; therefor , it is difficult to imagin our live without a comput . to learn ani profession cours , you must be well-vers in comput usag . whether a school student or an employe , you must at least know the basic of comput . along with the increas usag of comput , they have been updat in mani way , like make it lighter to carri in a bag , make processor faster , etc . with the increas usag and demand of peopl , comput have been develop and have made life easier . start from simpl calcul to weather forecast , comput have becom a part of our live .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data if not already present\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    \"\"\"\n",
    "    Apply stemming to the input text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be stemmed.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with all words stemmed.\n",
    "    \"\"\"\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Apply stemming to each token\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Join the stemmed tokens back into a single string\n",
    "    stemmed_text = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    return stemmed_text\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    # Define the path to your sample text file\n",
    "    file_path = 'sample.txt'\n",
    "    \n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "    \n",
    "    # Apply stemming\n",
    "    stemmed_text = stem_text(text)\n",
    "    \n",
    "    # Print the stemmed text\n",
    "    print(\"Stemmed Text:\")\n",
    "    print(stemmed_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.Lemmatization\n",
    "Lemmatization is a text processing technique that reduces words to their base or dictionary form (lemma), considering the context of the word, which helps in improving text analysis and consistency.\n",
    "\n",
    "**Tokenization**: The lemmatize_text function begins by tokenizing the input text into individual words using word_tokenize.\n",
    "\n",
    "**Lemmatization**: Each token is then lemmatized using the WordNet Lemmatizer, which reduces words to their base form based on their context.\n",
    "\n",
    "**Reconstruction**: The lemmatized words are combined back into a single string.\n",
    "\n",
    "**File Processing**: The main() function reads text from a file, applies lemmatization, and prints the lemmatized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mayal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Text:\n",
      "< ! DOCTYPE html > < html > < head > < title > Sample Document < /title > < /head > < body > < h1 > Welcome to Text Preprocessing ! < /h1 > < p > Text preprocessing involves various step such a cleaning , tokenization , stemming , and lemmatization. < /p > < p > Data from different source might include HTML tag , special character like @ , # , & , and emojis üòä. < /p > < p > Consider this sample sentence : `` I ca n't believe it 's already 2023 ! Text processing is awesome , is n't it ? `` < /p > < p > Also , name like maya , New Haven , and company such a apple are common entity in texts. < /p > < p > typo like this sentence need correction , and so doe spelling. < /p > < /body > < /html > A computer is one of the best man-made creation that ha been developed to help people in various sector . It ha become such an important part of our life that we find computer everywhere we go . Starting from our school life till our old age , we have many us for computer . We have become so much dependent on computer that we are using computer for almost everything we do . It is a device that can store an enormous amount of data in it . We are so much dependent on computer that we do not want to put any pressure on ourselves . We blindly store all our data in a computer with a safety passcode . A computer take up the responsibility and process the output in no time , hence making our life easier . It collect the data , process it and then provides the final result to u within a very short time . People in this day and age have become so reliant on computer that they can not imagine life without them . Computers are significant because of their widespread use , productivity , and openness . Computers are the most needed innovation due to their incredible benefit . Computers are used in every field , like the education sector , hospital , hotel , etc . If you go for a CT Scan , X-ray , or ECG , you will need a computer to check your body . In case you want to submit a project , you will need a computer . It ha become a part of our lifestyle . The computer is a remarkable piece of science that man ha created to help humanity . Computers are in charge of today ‚Äô s reality , and they have unquestionably altered people ‚Äô s lifestyle and the condition of developing country . In the 21st century , it is impossible to imagine a life without a computer and internet connection . The invention of computer ha brought a lot of change in people ‚Äô s life and ha helped in fulfilling people ‚Äô s dream . A computer is used in various organisation , school , institution , office , etc . It can be used to store important information with high protection and can also be used to send and receive message , make calculation , develop software , send and receive email , etc . The major part of a computer are the mouse , keyboard , monitor , and CPU , but these gadget have been improvised with a lot of modification . Nowadays , we have become very dependent on technology ; therefore , it is difficult to imagine our life without a computer . To learn any professional course , you must be well-versed in computer usage . Whether a school student or an employee , you must at least know the basic of computer . Along with the increasing usage of computer , they have been updated in many way , like making it lighter to carry in a bag , making processor faster , etc . With the increasing usage and demand of people , computer have been developed and have made life easier . Starting from simple calculation to weather forecasting , computer have become a part of our life .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK data if not already present\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Apply lemmatization to the input text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be lemmatized.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with all words lemmatized.\n",
    "    \"\"\"\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Apply lemmatization to each token\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join the lemmatized tokens back into a single string\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    return lemmatized_text\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def main():\n",
    "    # Define the path to your sample text file\n",
    "    file_path = 'sample.txt'\n",
    "    \n",
    "    # Read the content from the file\n",
    "    text = read_file(file_path)\n",
    "    \n",
    "    # Apply lemmatization\n",
    "    lemmatized_text = lemmatize_text(text)\n",
    "    \n",
    "    # Print the lemmatized text\n",
    "    print(\"Lemmatized Text:\")\n",
    "    print(lemmatized_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
